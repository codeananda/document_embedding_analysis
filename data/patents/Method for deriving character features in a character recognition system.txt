EP	0604687	B1	2000-04-19	en	TITLE	1	Method for deriving character features in a character recognition system
EP	0604687	B1	2000-04-19	en	DESCR	1	<heading id="h0001">A. <u>Background of the invention</u></heading><heading id="h0002">1. Field of the invention</heading><p id="p0001" num="0001">The invention is in the field of pattern recognition. It relates to a system for recognising characters, such as digits and letters, both in handwritten and printed form, and more particularly to a method for deriving features of a character to be recognised in a character recognition system of this type.</p><heading id="h0003">2. Prior art</heading><p id="p0002" num="0002">Character recognition systems such as those indicated above usually comprise a number of process steps which are described below with reference to a block diagram shown in Fig. 1. Said process steps are:<ul id="ul0001" list-style="none" compact="compact"><li>(1) optical scanning of a character on the surface of a carrier; such scanning, for example with a video camera, results in a two-dimensional pixel pattern, for example 64 Ã— 64 pixels, to which a grey value encoded in 5 bits is appended;</li><li>(2) binary quantisation of the pixel pattern, by subjecting the grey values of all the pixels to a threshold operation, the result, which can be seen as a black/white pattern or a pattern of "zeros" and "ones", being stored in a memory;</li><li>(3) deriving, from said quantised pixel pattern, an image description of the character to be recognised;</li><li>(4) deriving, from the image description, a set of character features of the character to be recognised;</li><li>(5) checking the set of character features found against results obtained previously with the aid of learning processes on known characters;<!-- EPO <DP n="2"> --></li><li>(6) deciding, on the basis of the check, which known character the character to be recognised is recognised as.</li></ul></p><p id="p0003" num="0003">A recognition technique of this type is known, for example, from reference [1] (cf. under C.). In this technique the quantised pixel pattern is used to derive a contour description. As a contour of a digitised pattern of a feature to be recognised is followed, the coordinates of certain points are selected. Those points are selected whose inner product of the point vector corresponding to each point and a directional vector in a number of predefined directions has the highest value. A selected point is characterised as an "extreme point" if the difference between said inner product at that point and the inner product at the following selected point exceeds a previously established limit value. Said extreme points define a polygonal approximation of the contour of the pattern. Said polygon shows a pattern of convex and concave structures. Said pattern is used for comparison with similar patterns, which are characteristic of known characters and stored in a previously compiled "dictionary". The character to be recognised is read as that known character whose patterns show the best correspondence.</p><p id="p0004" num="0004">A limitation of the pattern features derived in said known recognition technique is its being based on a structural description of the patterns to be recognised. This, however, produces acceptable recognition results only if the patterns to be recognised have a clear structure. This means that said known technique can be sensibly applied only for the recognition of characters from clear handwriting or typing. Another limitation is the variability of the number of features on which the recognition is based, i.e. the number of convex and concave structures in the pattern. This makes it difficult to apply deciders in the recognition, which work with a fixed number of features, such as, for example, those which make use of standard "feed-forward" neural<!-- EPO <DP n="3"> --> networks.</p><p id="p0005" num="0005">Reference [2] discloses another character recognition system of the above mentioned type. The recognition technique, on which this system is based, derives character features from a number of so-called views of an image, either the complete image or parts thereof, of a binary quantised pixel pattern of a character to be recognised. In this so-called views method, a number of different features of the pixel pattern is derived for each view, from above, from below and from the side, and for each image or part image. For these features, such as jumps, slopes, endpoints and islands, feature values are determined for specific patterns found in the views. During the check phase, the feature values found are weighted using adjustable weighting factors for each class of characters to be recognised. Said weighting factors have been obtained previously from a learning process on known characters. The weighted feature values are used to determine a score for each class. The character to be recognised is recognised as that character which belongs to the class in which the highest score has been determined.</p><p id="p0006" num="0006">This known technique, using the views method for deriving character features, has been developed in the first instance for recognising digits. The character features which are derived in this process have been found to be too general for acceptable letter recognition. Moreover, because of the many different features for which a character to be recognised has to be checked, the method for deriving the features is rather complex. Because of the type of the features, which are in fact structural features, a recognition based on said features is furthermore sensitive to breaks in an image pattern of a character to be recognised, and this recognition method is therefore unsuitable for, for example, matrix writing, such as, in particular, letters printed by a matrix printer.<!-- EPO <DP n="4"> --></p><p id="p0007" num="0007">In digital picture processing it is also known to make use of distance functions. Methods based thereon are sometimes denoted as "distance transform" or "distance mapping". A known "distance mapping" method of this type is, for example, disclosed by reference [3]. This involves appending to each pixel, which may form part of a subset of pixels, in the object (or in the background) of the original binary image, the shortest distance to the nearest pixel in the background (or the object). Corresponding to each point there is thus a distance tag. Further processing is then carried out on the basis of this two-component description, in which processing, inter alia, skeleton structures of the character to be recognised being traced. A distance tag of this type is inadequate per se as a character feature for the purpose of, in particular, recognising handwritten characters.</p><heading id="h0004">B. <u>Summary of the invention</u></heading><p id="p0008" num="0008">The object of the invention is to provide a method for deriving character features in a character recognition system, and a character recognition system in which this method is applied, which method and system do not have the above mentioned drawbacks and limitations. According to the invention, a method for deriving character features in a character recognition system for recognising characters, such as letters and digits, which comprises a step of deriving for each point of a plurality of points in an image plane of image points including a pattern of a character to be recognised feature data indicative of the distance to a nearest boundary point of the pattern, and which is known from reference [3], is, to this end, characterised according to Claim 1. An underlying idea in this context is that generally for such a reference point R<sub>i</sub> a nearest boundary point corresponds to a unique point of the image description of the character to be recognised, including its surroundings. By then considering the surroundings of such a unique point corresponding to a reference point R<sub>i</sub>, it is possible to select, in addition to the distance data D(R<sub>i</sub>), yet one or more additional features which may characterise the outline of the image description of the character in the vicinity of such a reference point. It was found that a very strong feature for this purpose is the feature which provides an estimate of the direction H(R<sub>i</sub>), which, if the image description of the character contains a contour description, has a contour in a unique<!-- EPO <DP n="5"> --> contour point corresponding to the reference point R<sub>i</sub>. Indeed, in a preferred embodiment the method according to the invention is characterised according to Claim 2.</p><p id="p0009" num="0009">Compared with the views method described above, the method according to the invention bases the recognition on a number of features which have been obtained, as it were, from local views of a character pattern, as seen from each of the reference points.</p><p id="p0010" num="0010">Reference [5] discloses a method for deriving features for the purpose of gray-level image recognition, in which features are determined in so called feature cells of which the locations for matching purposes are described by means of polar coordinates relative to an origin, called reference cell. The derived features are much more complicated than the features derived by the method of the present invention.</p><p id="p0011" num="0011">According to the invention, a character recognition system of a type indicated in the precharacterising clause of Claim 7 and which is known from reference [1] or [2], is, to this end, characterised as in Claim 7.</p><heading id="h0005">C. <u>References</u></heading><p id="p0012" num="0012"><ul id="ul0002" list-style="none" compact="compact"><li>[1] United States Patent document number 4,566,124, entitled "Pattern reading system";</li><li>[2] United States Patent document number 3,999,161, entitled "Method and device for the recognition of characters preferably of figures";</li><li>[3] P.-E. Danielsson, "Euclidean distance mapping, Computer Graphics and Image Processing 14, 227-248 (1980);</li><li>[4] R. P. Lippmann, "An introduction to computing with neural nets", IEEE ASSP Magazine, April 1987, pp. 4-22;</li><li>[5] M. Sano, et al., "Gray-level image recognition based on multiple cell-features", Systems and Computers in Japan, 22(1991) No. 5, New York, US, pp. 81-93.</li></ul></p><heading id="h0006">D. <u>Brief description of the drawings</u></heading><p id="p0013" num="0013">The invention will be explained in more detail by means of a description of an illustrative embodiment, with reference to a drawing in<!-- EPO <DP n="6"> --> which:<dl id="dl0001" compact="compact"><dt>Fig. 1</dt><dd>shows a block diagram of process steps of a character recognition system;</dd><dt>Fig. 2</dt><dd>represents a black/white pixel image of a character to be recognised having an inner and an outer contour;</dd><dt>Fig. 3</dt><dd>illustrates a process of tracing a contour, Fig. 3a showing the situation for a single black pixel, and Fig. 3b showing the situation after a kth contour point has been found;</dd><dt>Fig. 4</dt><dd>represents the contour outline after filtering of the contours of the pixel image according to Fig. 2;</dd><dt>Fig. 5</dt><dd>shows, in the subsections Figs 5a, 5b and 5c, three different situations of the position of a reference point with regard to a contour chord;</dd><dt>Fig. 6</dt><dd>shows an overview as a block diagram of processor and memory means for the specific purpose of carrying out the process steps (3) and (4) from Fig. 1 according to the invention;</dd><dt>Fig. 7</dt><dd>shows a diagram of a decider for carrying out the process steps (5) and (6) according to Fig. 1, as applied in combination with the method according to the invention.</dd></dl></p><heading id="h0007">E. <u>Description of an illustrative embodiment</u></heading><p id="p0014" num="0014">The invention relates to a method for deriving character features for the purpose of a recognition system for recognising characters, such as, for example, printed or handwritten digits and letters. Starting from a description of a character to be recognised, the recognition proceeds on the basis of a number of features, derived within suitably determined boundary points, of the described character. The invention therefore relates, in the first instance, to process step (4) in the character recognition system described with<!-- EPO <DP n="7"> --> reference to Fig. 1. The invention can be applied both to a pixel description and to a contour description of a character to be recognised. This relates to process step (3). Since a contour approach is preferred, it will be described in detail hereinafter, while the pixel approach will only be hinted at. The process steps (1) and (2) are carried out according to known techniques by recording means which are known per se and are therefore not described in further detail here. In the further description of an illustrative embodiment it is assumed that these steps have taken place and that a black/white pixel pattern of a character to be recognised has been stored in a two-dimensional image memory and is accessible for further operations. Such a black/white pixel pattern in an image plane comprising LxM pixels has an elementary description, called the pixel description, by means of a function B(i,j), of pixel values for each pixel (i,j) in the image plane, where i=1,--,L, and j=1,--,M, which function is defined by B(i,j)=1 for each black pixel (i,j) and B(i,j)=0 for each white pixel (i,j) in the image plane.</p><p id="p0015" num="0015">It is further assumed that, if the character to be recognised is part of a row of simultaneously recorded characters, a segmentation operation has already been carried out on said row, according to techniques known per se, in order to separate the characters and make them suitable for separate treatment. The process steps (5) and (6) are also carried out by known techniques. Since, however, the checking and decision means required there-for must previously have been learnt, so that certain characters may be recognised on the basis of the character features derived according to the method according to the invention, such means will be briefly explained in more detail following a full description of the method.</p><p id="p0016" num="0016">In the field of image processing and pattern recognition, the so-called distance transform is known. This transform appends a number D(P) to each<!-- EPO <DP n="8"> --> point P in an image plane of a black-and-white pattern of image points, in the following way:<ul id="ul0003" list-style="dash" compact="compact"><li>if the point P is situated in a white area of the image plane, then D(P) is equal to the distance to the nearest black image point; and</li><li>if the point P is situated in a black area which, for example, represents a digit or a letter, then D(P) is equal to the distance to the nearest white image point, provided with a minus sign.</li></ul></p><p id="p0017" num="0017">This distance transform is often used in so-called skeleton algorithms for tracing skeleton structures, the character recognition then being carried out on the basis of the skeleton structures found. An image signal thus transformed is also sometimes used directly for the purpose of the recognition process. A distance tag is then used as a character feature. If a limited number of image points is included in the process, for example to speed up the arithmetic operation, the distance tag is insufficient for describing a character to be recognised. To achieve an acceptable recognition probability, very large numbers, if not all, of the image points are therefore included in the transform. Nevertheless, the recognition of, in particular, handwriting is insufficient. The object of the invention, however, is to achieve a considerably higher recognition probability by appending one or more additional character features to each distance tag obtained on the basis of a distance transform on a limited number N of points R<sub>i</sub>, which have been preselected in a suitable way (where i=1,2,--,N), and which are called reference points, in the image plane.</p><p id="p0018" num="0018">This is based on the idea that, if such a reference point R<sub>i</sub> has a distance tag D(R<sub>i</sub>) appended to it, in general a unique boundary point P<sub>i</sub> of a character to be recognised will correspond thereto, including its surroundings. Boundary points are to be understood as those image points which have both white and black image points in their direct surroundings. In the case of a contour<!-- EPO <DP n="9"> --> description, a boundary point is a point on the contour, a contour point. Unless stated otherwise, from now on, a contour description and contour points will be assumed. By then considering the surroundings of a unique contour point P<sub>i</sub> of this type and corresponding to a reference point R<sub>i</sub>, it is possible to append, to the distance tag D(R<sub>i</sub>), one or more additional features, which, seen from such a reference point R<sub>i</sub>, describe the outline of the nearest contour segment C(R<sub>i</sub>). It was found that a very strong feature therefor is the feature which provides an estimate of the direction H(R<sub>i</sub>) of the contour in the contour point P<sub>i</sub>. Other supplementary features to be named, also those which provide an estimate of the second and third derivative of the contour in the contour point P<sub>i</sub>. Said supplementary features, however, do not provide much of an additional contribution to increasing the recognition probability of a character. All these descriptions, on the basis of said additional features, of the said nearest contour segments C(R<sub>i</sub>) for all the N reference points R<sub>i</sub> together are found to enable very effective recognition if N is sufficiently large. From 70 to 120 reference points are preferably used for each character, which points may be distributed regularly or randomly over the image plane.</p><p id="p0019" num="0019">In an example given below, the method for determining the features D(R<sub>i</sub>) and H(R<sub>i</sub>) for a reference point R<sub>i</sub> in the image plane of a pattern to be recognised will be explained in more detail.</p><p id="p0020" num="0020">For this purpose, Fig. 2 shows a black-and-white pattern of a separate character in a rectangle of 12 fields by 16, each field corresponding to a pixel. For the sake of clarity, the number of pixels in this example has been kept small. Each field is uniquely identifiable by means of its centre coordinates (i,j), where i=1,--,12 and j=1,--,16. The black fields are hatched. Each field is black or white. Thus field (2,3) is white and field (4,3) is black. If a field (i,j) is black, then it has a pixel value B(i,j)=1; and, if it is white, then it has the<!-- EPO <DP n="10"> --> pixel value B(i,j)=0. Where a black field adjoins a white field, the boundary lines are drawn as bold lines. Said two-dimensional description is then converted, by means of a process which is called contour tracer, into a one-dimensional contour description of the pattern of the character to be recognised. Said contour tracer successively runs through all the 12 Ã— 16 fields of the pixel image wile looking for contour points. Each time a starting point is found, a contour is generated. In this process, the contours are given a number, and their relative position is established by remembering whether a starting point found is situated within a previously determined contour. The process of tracing a contour is now explained in more detail with reference to Fig. 3 with sections 3a and 3b. In this process, each pixel is regarded as a black or white small square of finite dimensions. The corners of such a square are called grid points. In Fig. 3a, a single black pixel having centre coordinates (i,j) is shown as a hatched small square, with numbered grid points 1 to 4 inclusive. A separate black pixel by itself already has a well-defined contour, which is formed by the boldly drawn periphery segments from 1 to 2, from 2 to 3, etc., which encloses the black area in a clockwise direction (according to the direction of the arrow). The x,y coordinates of said four contour grid points 1 to 4 inclusive are chosen as:<maths id="math0001" num=""><math display="block"><mrow><mtable><mtr><mtd><mrow><mtable><mtr><mtd><mrow><mtext>(x(1),y(1)) = (i-0.5,j+0.5)</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>(x(2),y(2)) = (i+0.5,j+0.5)</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>(x(3),y(3)) = (i+0.5,j-0.5)</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>(x(4),y(4)) = (i-0.5,j-0.5)</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mrow></math><img id="ib0001" file="imgb0001.tif" wi="52" he="26" img-content="math" img-format="tif"/></maths></p><p id="p0021" num="0021">In Fig. 3b the situation is shown where, when tracing a contour C after the (k-2)th and the (k-1)th contour grid point, when coming from an arrival direction v, a grid point (x(k),y(k)) has been found as the kth contour point. The arrival direction <maths id="math0002" num=""><math display="inline"><mrow><mtext>v = (vx,vy)</mtext></mrow></math><img id="ib0002" file="imgb0002.tif" wi="21" he="5" img-content="math" img-format="tif" inline="yes"/></maths> has four possible values, which can be<!-- EPO <DP n="11"> --> expressed as follows: (1,0), (-1,0), (0,1) and (0,-1). In the example drawn it is (1,0). To the left and to the right of the continuation of the arrival direction v, past the kth contour point, two pixels L and R are shown as broken lines.</p><p id="p0022" num="0022">Three directions are possible, in which the following (k+1)th contour point may be found, shown in the figure as v<sub>1</sub>, v<sub>2</sub> and v<sub>3</sub>. The direction in which the following contour point is found depends on the pixel value B of each of the pixels L and R. The centre coordinates of the pixels L and R, given the arrival direction (vx, vy) and the coordinates of the kth contour grid points, are:<maths id="math0003" num=""><math display="block"><mrow><mtable><mtr><mtd><mrow><mtable><mtr><mtd><mrow><mtext>iL = x(k) + (vx-vy)/2 and jL = y(k) + (vx+vy)/2</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>iR = x(k) + (vx=vy)/2 and jR = y(k) + (vx-vy)/2</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mrow></math><img id="ib0003" file="imgb0003.tif" wi="97" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0023" num="0023">The (k+1)th contour grid point and associated arrival direction are determined by means of a contour tracing algorithm, which may have the following appearance:<ul id="ul0004" list-style="none" compact="compact"><li><u>if</u> B(iL,jL) = 1 <u>then begin</u> vx := -vy; vy := vx <u>end</u> <u>else</u></li><li><u>if</u> B(iR,jR) = 0 <u>then</u> <u>begin</u> vx:= vy; vy := -vx <u>end</u>;</li><li>x(k+1) :=x(k) + vx; y(k+1) := y(k) + vy; k := k+1;<br/>continue to next point;</li></ul></p><p id="p0024" num="0024">To find the contours of a pixel image such as that shown in Fig. 2, the image plane is scanned from left to right and from top to bottom. A first starting point for a contour is found if, during this scan, the first black pixel, in the example pixel (6,14), is found. The first two contour points selected in this case are those corresponding to contour grid points 1 and 2 in Fig. 3a, with v = (1,0) as arrival direction in the second contour grid point. The contour tracing algorithm is then started until a return is made to the first contour<!-- EPO <DP n="12"> --> grid point. For each new start of the contour tracing algorithm, a contour number CN is increased by one. During each execution of the contour tracing algorithm, the pixels which belong to the same contour are marked with the same contour number CN. This marking is remembered in a separate, second image memory. Prior to the commencement of scanning of the image plane, all the pixels in the second image memory have the same initial mark, for example zero. After completion of a contour, the pixel image is scanned further in the search for a starting point for a next contour. The next starting point is found if, during further scanning, a black pixel is found which has not yet been marked, or if an unmarked white pixel is found within a previously found contour. In such a case the tracing algorithm is again run through. During the run-through, all the contour grid points found are recorded, in the order found, in a contour table, including an associated contour account. Said account comprises, for each contour, the number CN of the contour, pointers nrept and nrlpt to the first and last contour grid point of the contour in question, respectively, and a code cdoc which indicates the number of the immediately surrounding contour. The periphery of the whole pixel image is considered, in this context, as a virtual contour having the number 0. The pixel image of Fig. 2 has a first contour C1, whose contour grid points are successively numbered 1, 2, 3, --, 61 and 62. It has a second contour C2, whose contour grid points are numbered 63, 64, --, 77 and 78, and which is entirely situated within the first contour C1. The associated contour table is shown in Table 1 with subsections 1a and 1b, the contour account being incorporated in subsection 1a, and Table 1b forming the list of contour grid points.</p><p id="p0025" num="0025">By way of example, assume a set RP of reference points RP(m,n), comprising a number of pixel centres:<!-- EPO <DP n="13"> --><maths id="math0004" num=""><math display="block"><mrow><mtext>RP = {RP(m,n) = (4m-2,5n-2)|m,n = 1,2,3}</mtext></mrow></math><img id="ib0004" file="imgb0004.tif" wi="79" he="5" img-content="math" img-format="tif"/></maths></p><p id="p0026" num="0026">One of said reference points, RP(3,2), has been drawn in Fig. 2. If, from such a point, the local shape of the closest contour segment, in this case of contour C1, is investigated, features are obtained of a rather angular and busy pattern. Therefore, prior to commencing the feature derivation proper, the contour description obtained by the above contour tracing algorithm is first supplied to what can be called a contour filtering process, which produces a contour with a quieter outline. This is carried out, again by way of example, with a simple linear filter which, running along the contour, always determines a weighted mean of the corresponding contour grid points. In this process, the filtering step is always carried out with an offset of one grid spacing. The result of this filtering is a new, equally long list of contour points, which are usually no longer grid points, and which form the corners of a polygon with a quiet outline. If the length of such a linear filter is chosen to be four grid units, each filtering step always involves five successive contour grid points from the contour table. A new contour table is compiled by appending, new coordinates to the coordinates of each kth contour grid point in the now old contour table by:<maths id="math0005" num=""><math display="block"><mrow><mtable><mtr><mtd><mrow><mtable><mtr><mtd><mrow><mtext>X(k) = x(k-2)/8 + x(k-1)/4 + x(k)/4 + x(k+1)/4 + x(k+2)/8</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>Y(k) = y(k-2)/8 + y(k-1)/4 + y(k)/4 + y(k+1)/4 + y(k+2)/8</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mrow></math><img id="ib0005" file="imgb0005.tif" wi="115" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0027" num="0027">When applied to the image pattern shown in Fig. 2 with the contour table according to Table 1b, this produces a new contour outline which is depicted in Fig. 4, and whose associated contour table is shown in Table 2 with the list of new coordinates of the contour points. The contour account in this case has remained unchanged.<!-- EPO <DP n="14"> --> It is the case that the contour description is more suitable for the derivation proper of local contour features D and H for each of the reference points of the set RP. In this process, each contour is regarded as being composed of chords. A chord, with the number k, is the straight connection line segment between two successive numbered contour points k-1 and k, including the contour point k as the end point, and excluding the contour point k-1 as the starting point. The list of contour points in the contour table thus becomes a list of end points of successive chords which constitute the contours specified in the contour account. It is then determined, for each reference point from the set RP, which of the chords of all the contours in the contour table the reference point Dmin(RQ) is at the shortest distance from as well as said shortest distance itself. This is achieved by running successively through the list of end points of the chords. Depending on the position of a reference point RQ with regard to a chord k, three different situations may arise. These are shown diagrammatically in Fig. 5 with subsections 5a, 5b and 5c. In the situation according to Fig. 5a, the most closely situated point is in fact the starting point of the chord k. The minimum distance Dmin(RQ) found so far has therefore already been determined in the case of a preceding chord. In the situations according to Figs 5b and 5c, respectively, a point P of the chord k and the end point of the chord k are the nearest points which are at a distance d from the reference point RQ. In both cases a test is then carried out to discover whether this distance d found is shorter than the minimum distance Dmin(RQ) previously recorded so far. If so, the distance d found is recorded as the new value for Dmin(RQ), together with the associated chord number.</p><p id="p0028" num="0028">The following formulae are used for calculating the distance: in the situation according to Fig. 5b:<maths id="math0006" num=""><math display="block"><mrow><msup><mrow><mtext>d</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext> = (ax * cy - ay * cx)</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext>/(cx</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext> +cy</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><mtext>)</mtext></mrow></math><img id="ib0006" file="imgb0006.tif" wi="69" he="6" img-content="math" img-format="tif"/></maths><!-- EPO <DP n="15"> --> and in the situation according to Fig. 5c:<maths id="math0007" num=""><math display="block"><mrow><msup><mrow><mtext>d</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext> = ax</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext> + ay</mtext></mrow><mrow><mtext>2</mtext></mrow></msup></mrow></math><img id="ib0007" file="imgb0007.tif" wi="29" he="6" img-content="math" img-format="tif"/></maths> in which:<maths id="math0008" num=""><math display="block"><mrow><mtable><mtr><mtd><mrow><mtable><mtr><mtd><mrow><mtext>ax = x(RQ) - X(k) and ay = y(RQ) - Y(k)</mtext></mrow></mtd></mtr><mtr><mtd><mrow><mtext>cx = X(k) - X(k-1) and cy = Y(k) - Y(k-1)</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mrow></math><img id="ib0008" file="imgb0008.tif" wi="88" he="14" img-content="math" img-format="tif"/></maths></p><p id="p0029" num="0029">In fact, the minimum d<sup>2</sup> is first determined, and only if this has been found is its root calculated. At the same time, the process checks whether the reference point RQ in question is located to the left or the right of the contour of which the chord with the minimum distance Dmin(RQ) forms part. This is done by determining the inner product (ax * cy - ay * cx) of the vector (cy,cx) perpendicular to the chord, which is now interpreted as a vector (cx,cy), with the vector (ax,ay) defined by the end point of the chord and the reference point RQ. If the value of the inner product is positive, the reference point RQ is located to the right and, if negative, to the left of the contour. Since a contour is always chosen clockwise around black, it is then known whether the reference point RQ in question is situated in a "black" or in a "white" area of the filtered image pattern.</p><p id="p0030" num="0030">The desired features at the reference point RQ are now determined as follows:<ul id="ul0005" list-style="none"><li>(i)<dl id="dl0002" compact="compact"><dt>D (RQ) =</dt><dd>Dmin(RQ) if RQ is in a "white" area;</dd><dt>D (RQ) =</dt><dd>-Dmin(RQ) if RQ is in a "black" area;</dd></dl></li><li>(ii)<dl id="dl0003" compact="compact"><dt>H (RQ) =</dt><dd>direction of the nearest chord found, which is calculated as the direction of the vector [X(k) - X(k-1), Y(k) - Y(k-1)] in the situation according to Fig. 5b;</dd><dt>H(RQ) =</dt><dd>direction of the vector perpendicular to the connecting line between the end point of the nearest<!-- EPO <DP n="16"> --> chord and the reference point RQ, which is calculated as the direction of the vector Â±[Y(k) - Y(RQ), -X(k) + X(RQ)] in the situation according to Fig. 5c, the plus/minus sign applying according to whether the reference point RQ is situated in "black" or "white", respectively.</dd></dl></li></ul></p><p id="p0031" num="0031">The direction feature is preferably expressed as an angle, and it can be calculated, for example, by means of a <maths id="math0009" num=""><math display="inline"><mrow><msup><mrow><mtext>cos</mtext></mrow><mrow><mtext>-1</mtext></mrow></msup></mrow></math><img id="ib0009" file="imgb0009.tif" wi="8" he="5" img-content="math" img-format="tif" inline="yes"/></maths>, a <maths id="math0010" num=""><math display="inline"><mrow><msup><mrow><mtext>sin</mtext></mrow><mrow><mtext>-1</mtext></mrow></msup></mrow></math><img id="ib0010" file="imgb0010.tif" wi="7" he="5" img-content="math" img-format="tif" inline="yes"/></maths> or a <maths id="math0011" num=""><math display="inline"><mrow><msup><mrow><mtext>tan</mtext></mrow><mrow><mtext>-1</mtext></mrow></msup></mrow></math><img id="ib0011" file="imgb0011.tif" wi="8" he="5" img-content="math" img-format="tif" inline="yes"/></maths> function.</p><p id="p0032" num="0032">When applied to the filtered contour description as shown in Fig. 4, it is found for a reference point RP(3,2) that the chord having number 14 are at the shortest distance. Since the reference point is located in "white" the minimum distance is to be regarded as positive, and the direction feature <maths id="math0012" num=""><math display="inline"><mrow><mtext>H(RP(3,2)) = direction of the vector [X(14) - X(13), Y(14) - Y(13)]</mtext></mrow></math><img id="ib0012" file="imgb0012.tif" wi="126" he="5" img-content="math" img-format="tif" inline="yes"/></maths> .</p><p id="p0033" num="0033">As already mentioned previously, the method according to the invention can be carried out not only with a contour description of an image pattern. A description on a pixel basis, the pixel description B(i,j), is similarly directly suitable for determining the features D(RQ) and H(RQ). In the case of this description, it is, moreover, possible to make use of one of the many known algorithms for determining the distance transform. If pixel centres are again<ul id="ul0006" list-style="none" compact="compact"><li>chosen as reference points, a simple algorithm can proceed as follows: if a reference point RQ is located in "white', the pixel surroundings round the reference point RQ are scanned in steadily increasing "circles" until the nearest "black" pixel Z has been found. Then the features are chosen as follows:<maths id="math0013" num=""><math display="block"><mrow><msup><mrow><mtext>D(RQ) = {(i(Z) - i(RQ))</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext> + (j(z) - j(RQ))</mtext></mrow><mrow><mtext>2</mtext></mrow></msup><msup><mrow><mtext>}</mtext></mrow><mrow><mtext>Â½</mtext></mrow></msup></mrow></math><img id="ib0013" file="imgb0013.tif" wi="83" he="6" img-content="math" img-format="tif"/></maths> and<maths id="math0014" num=""><math display="block"><mrow><mtext>H(RQ) = direction of the vector [-j(Z) + j(RQ), i(Z) - i(RQ)]</mtext></mrow></math><img id="ib0014" file="imgb0014.tif" wi="113" he="5" img-content="math" img-format="tif"/></maths></li></ul><!-- EPO <DP n="17"> --></p><p id="p0034" num="0034">If RQ is situated in a "black" area, the nearest "white" pixel W is, of course, searched for, and the analogous expressions then apply for the features. The above mentioned selection for the directional feature H(RQ) is very simple, but rather coarse. Refinements can be obtained by including surrounding points of Z or W, whose pixel value correlates with Z or W.</p><p id="p0035" num="0035">The features obtained according to the manner described above, on the basis of either a pixel description or a contour description of a character to be recognised, form the elements of a vector, the feature vector V = {v<sub>n</sub>} with n=1,--,2N, the row of vector coefficients being chosen as<maths id="math0015" num=""><math display="block"><mrow><msub><mrow><mtext>{v</mtext></mrow><mrow><mtext>n</mtext></mrow></msub><msub><mrow><mtext>} = {D(R</mtext></mrow><mrow><mtext>1</mtext></mrow></msub><msub><mrow><mtext>), H(R</mtext></mrow><mrow><mtext>1</mtext></mrow></msub><msub><mrow><mtext>), D(R</mtext></mrow><mrow><mtext>2</mtext></mrow></msub><msub><mrow><mtext>), H(R</mtext></mrow><mrow><mtext>2</mtext></mrow></msub><msub><mrow><mtext>),--, D(R</mtext></mrow><mrow><mtext>N</mtext></mrow></msub><msub><mrow><mtext>), H(R</mtext></mrow><mrow><mtext>N</mtext></mrow></msub><mtext>)}.</mtext></mrow></math><img id="ib0015" file="imgb0015.tif" wi="104" he="6" img-content="math" img-format="tif"/></maths></p><p id="p0036" num="0036">Figure 6 shows, as a block diagram, an overview of processor means PM and of memory means MM, which are specific for carrying out the process steps (3) and (4) from Fig. 1 according to the method described above for deriving character features. Below a broken dashed line, the memory means are shown, indicated by M1, M2, M3 and M4, and above said dashed line are shown the processor means PM for carrying out three processes indicated by CD, CF and FD. The relationship is as follows. The process CD describes the contour of a character. It carries out the contour tracing algorithm on the image pattern of the character which, after process steps (1) and (2) from Fig. 1 have been carried out, is available in a first memory M1, the image memory; and it puts the contour description obtained into a second memory M2. Then the process CF carries out the contour filtering process on the contour description put into the second memory M2, and puts the filtered contour description thus obtained into a third memory M3. Stored in a fourth memory M4 is a list with coordinate data of the reference points R<sub>i</sub> of the set RP. The process FD carries out the feature derivation for all the reference<!-- EPO <DP n="18"> --> points from the list in the fourth memory M4 on the filtered contour description present in the third memory, and outputs the feature vector V thus found.</p><p id="p0037" num="0037">The feature vector V is subsequently presented to combined checking and decision means, designated decider 100, of which a diagram is shown in Fig. 7, for carrying out the process steps (5) and (6) of Fig. 1. The decider 100 comprises a feature checker 101 and a maximum selector 102. The feature checker has as many inputs I<sub>n</sub> as the feature vector V has coefficients, in the present example, therefore, 2N, for receiving all the coefficients v<sub>n</sub>, the derived feature values; and as many outputs u<sub>m</sub> as the total number M of characters to be recognised. Said number M is, for example, 34, if the set of characters to be recognised is formed by the digits 0, 1, --, 9 and the capital letters A, B, --, Z. For each feature vector V presented at the input of the feature checker 101, the latter determines a score vector <maths id="math0016" num=""><math display="inline"><mrow><msub><mrow><mtext>S = {s</mtext></mrow><mrow><mtext>m</mtext></mrow></msub><mtext>|m=1,--,M}</mtext></mrow></math><img id="ib0016" file="imgb0016.tif" wi="34" he="6" img-content="math" img-format="tif" inline="yes"/></maths> , each coefficient s<sub>m</sub> of which expresses the measure, according to which the presented feature vector V fits the mth character from the set of characters to be recognised. The coefficients of the score vector S are presented, via the outputs u<sub>m</sub>, to the maximimum selector 102. Said maximum selector 102 determines the largest of the coefficients s<sub>m</sub> and outputs a signal CH at its output 103, according to the character from the character set to be recognised, which corresponds to the determined largest coefficient. The feature checker is preferably a multi-larger neural network, e.g. composed of three layers of perceptrons, as disclosed, for example, by reference [4]. In FIG. 7, however, the feature checker 101 has been shown simply only as a single-layer neural network having a number M of perceptrons. Three steps are to be distinguished in the feature checker 101, viz.:<ul id="ul0007" list-style="dash" compact="compact"><li>a distribution step, denoted by the letter T;<!-- EPO <DP n="19"> --></li><li>a weighting step, denoted by the letter W; and</li><li>a summation step, denoted by the letter Î£.</li></ul></p><p id="p0038" num="0038">The feature values presented with the feature vector V to the feature checker 101 are, as derived, continuous values. In the distribution step T each presented value v<sub>n</sub> is, as it were, distributed by distribution units t<sub>n</sub>(n=1,--,2N) by presenting the same value in a multiple way, viz. in M directions, i.e. as many as there are perceptrons. During the weigthing step W each feature value v<sub>n</sub> in each direction m is weighted by means of a weighting factor W<sub>nm</sub> from a set of weighting factors {W<sub>nm</sub>}. This set of weighting factors in fact forms a dimensional array, the weighting factor matrix, where n=1,--,2N is the number of a presented feature value v<sub>n</sub>, and m=1,--,M is the number of a character to be recognised in the set of characters to be recognised. With the aid of the weighting factors, a score is then determined in the summation step Î£ by each one of a number M of summators Ïƒ<sub>m</sub>, which score forms the previously mentioned coefficient s<sub>m</sub> of the score vector S. For each summator Ïƒ<sub>m</sub>, this score is:<maths id="math0017" num=""><math display="block"><mrow><msub><mrow><mtext>s</mtext></mrow><mrow><mtext>m</mtext></mrow></msub><msub><mrow><mtext>=f(Î£w</mtext></mrow><mrow><mtext>nm</mtext></mrow></msub><msub><mrow><mtext>*v</mtext></mrow><mrow><mtext>n</mtext></mrow></msub><mtext>)</mtext></mrow></math><img id="ib0017" file="imgb0017.tif" wi="26" he="6" img-content="math" img-format="tif"/></maths> in which the summation is carried out over all n=1,--,2N and f represents a non-linear function such as a sigmoid. This is indicated in FIG. 7 by arrows from each distribution unit t<sub>n</sub> to each of the summators Ïƒ<sub>m</sub>. The arrows here are provided with their associated weighting factor from the weighting factor matrix.</p><p id="p0039" num="0039">The coefficients s<sub>m</sub> of the score vector S are presented to the maximum selector 102. The weighting factor matrix {w<sub>nm</sub>} is located in a memory accessible to the decider. The coefficients of this matrix have been predetermined according to a training algorithm which is known as the "back propagation containing algorithm" (see, for example, reference [4], particularly<!-- EPO <DP n="20"> --> Box 6.). In that case, character features were presented to the decider of known characters from a training set of known characters, which had been derived with the aid of the new method described above.</p><p id="p0040" num="0040">When applied to a large test set of practice material (approximately 200,000) of readily separable handwritten digits, a character recognition system, which worked with the new method for deriving the character features "distance" and "direction", was found to satisfactorily recognise 99.3% of the characters presented. If only the character feature "distance" was used, the maximum yield was found to be 98.6%.<!-- EPO <DP n="21"> --> <tables id="tabl0001" num="0001"><table frame="all"><title>Table 1a</title><tgroup cols="4" colsep="1" rowsep="0"><colspec colnum="1" colname="col1" colwidth="39.37mm"/><colspec colnum="2" colname="col2" colwidth="39.37mm"/><colspec colnum="3" colname="col3" colwidth="39.37mm"/><colspec colnum="4" colname="col4" colwidth="39.37mm"/><thead valign="top"><row rowsep="1"><entry namest="col1" nameend="col1" align="center">CN</entry><entry namest="col2" nameend="col2" align="center">nrept</entry><entry namest="col3" nameend="col3" align="center">nrlpt</entry><entry namest="col4" nameend="col4" align="center">cdoc</entry></row></thead><tbody valign="top"><row><entry namest="col1" nameend="col1" align="right">1</entry><entry namest="col2" nameend="col2" align="center">1</entry><entry namest="col3" nameend="col3" align="right">62</entry><entry namest="col4" nameend="col4" align="right">0</entry></row><row rowsep="1"><entry namest="col1" nameend="col1" align="right">2</entry><entry namest="col2" nameend="col2" align="center">63</entry><entry namest="col3" nameend="col3" align="right">78</entry><entry namest="col4" nameend="col4" align="right">1</entry></row></tbody></tgroup></table></tables> <tables id="tabl0002" num="0002"><table frame="all"><title>Table 1b</title><tgroup cols="3" colsep="1" rowsep="0"><colspec colnum="1" colname="col1" colwidth="52.50mm"/><colspec colnum="2" colname="col2" colwidth="52.50mm"/><colspec colnum="3" colname="col3" colwidth="52.50mm"/><thead valign="top"><row rowsep="1"><entry namest="col1" nameend="col1" align="center">k</entry><entry namest="col2" nameend="col2" align="center">x</entry><entry namest="col3" nameend="col3" align="center">y</entry></row></thead><tbody valign="top"><row><entry namest="col1" nameend="col1" align="center">1</entry><entry namest="col2" nameend="col2" align="char" char=".">5.5</entry><entry namest="col3" nameend="col3" align="char" char=".">14.5</entry></row><row><entry namest="col1" nameend="col1" align="center">2</entry><entry namest="col2" nameend="col2" align="char" char=".">6.5</entry><entry namest="col3" nameend="col3" align="char" char=".">14.5</entry></row><row><entry namest="col1" nameend="col1" align="center">3</entry><entry namest="col2" nameend="col2" align="char" char=".">7.5</entry><entry namest="col3" nameend="col3" align="char" char=".">14.5</entry></row><row><entry namest="col1" nameend="col1" align="center">4</entry><entry namest="col2" nameend="col2" align="char" char=".">8.5</entry><entry namest="col3" nameend="col3" align="char" char=".">14.5</entry></row><row><entry namest="col1" nameend="col1" align="center">5</entry><entry namest="col2" nameend="col2" align="char" char=".">8.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row><entry namest="col1" nameend="col1" align="center">6</entry><entry namest="col2" nameend="col2" align="char" char=".">9.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row><entry namest="col1" nameend="col1" align="center">7</entry><entry namest="col2" nameend="col2" align="char" char=".">9.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">60</entry><entry namest="col2" nameend="col2" align="char" char=".">3.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row><entry namest="col1" nameend="col1" align="center">61</entry><entry namest="col2" nameend="col2" align="char" char=".">4.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row rowsep="1"><entry namest="col1" nameend="col1" align="center">62</entry><entry namest="col2" nameend="col2" align="char" char=".">5.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row><entry namest="col1" nameend="col1" align="center">63</entry><entry namest="col2" nameend="col2" align="char" char=".">6.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row><entry namest="col1" nameend="col1" align="center">64</entry><entry namest="col2" nameend="col2" align="char" char=".">6.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">65</entry><entry namest="col2" nameend="col2" align="char" char=".">5.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">76</entry><entry namest="col2" nameend="col2" align="char" char=".">8.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">77</entry><entry namest="col2" nameend="col2" align="char" char=".">7.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row rowsep="1"><entry namest="col1" nameend="col1" align="center">78</entry><entry namest="col2" nameend="col2" align="char" char=".">7.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row></tbody></tgroup></table></tables><!-- EPO <DP n="22"> --> <tables id="tabl0003" num="0003"><table frame="all"><title>Table 2</title><tgroup cols="3" colsep="1" rowsep="0"><colspec colnum="1" colname="col1" colwidth="52.50mm"/><colspec colnum="2" colname="col2" colwidth="52.50mm"/><colspec colnum="3" colname="col3" colwidth="52.50mm"/><thead valign="top"><row rowsep="1"><entry namest="col1" nameend="col1" align="center">k</entry><entry namest="col2" nameend="col2" align="center">X</entry><entry namest="col3" nameend="col3" align="center">Y</entry></row></thead><tbody valign="top"><row><entry namest="col1" nameend="col1" align="center">1</entry><entry namest="col2" nameend="col2" align="char" char=".">5.875</entry><entry namest="col3" nameend="col3" align="char" char=".">14.125</entry></row><row><entry namest="col1" nameend="col1" align="center">2</entry><entry namest="col2" nameend="col2" align="char" char=".">6.625</entry><entry namest="col3" nameend="col3" align="char" char=".">14.375</entry></row><row><entry namest="col1" nameend="col1" align="center">3</entry><entry namest="col2" nameend="col2" align="char" char=".">7.375</entry><entry namest="col3" nameend="col3" align="char" char=".">14.375</entry></row><row><entry namest="col1" nameend="col1" align="center">4</entry><entry namest="col2" nameend="col2" align="char" char=".">8.125</entry><entry namest="col3" nameend="col3" align="char" char=".">14.125</entry></row><row><entry namest="col1" nameend="col1" align="center">5</entry><entry namest="col2" nameend="col2" align="char" char=".">8.750</entry><entry namest="col3" nameend="col3" align="char" char=".">13.75</entry></row><row><entry namest="col1" nameend="col1" align="center">6</entry><entry namest="col2" nameend="col2" align="char" char=".">9.125</entry><entry namest="col3" nameend="col3" align="char" char=".">13.125</entry></row><row><entry namest="col1" nameend="col1" align="center">7</entry><entry namest="col2" nameend="col2" align="char" char=".">9.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">60</entry><entry namest="col2" nameend="col2" align="char" char=".">3.875</entry><entry namest="col3" nameend="col3" align="char" char=".">13.125</entry></row><row><entry namest="col1" nameend="col1" align="center">61</entry><entry namest="col2" nameend="col2" align="char" char=".">4.5</entry><entry namest="col3" nameend="col3" align="char" char=".">13.5</entry></row><row rowsep="1"><entry namest="col1" nameend="col1" align="center">62</entry><entry namest="col2" nameend="col2" align="char" char=".">5.125</entry><entry namest="col3" nameend="col3" align="char" char=".">13.875</entry></row><row><entry namest="col1" nameend="col1" align="center">63</entry><entry namest="col2" nameend="col2" align="char" char=".">6.75</entry><entry namest="col3" nameend="col3" align="char" char=".">13.0</entry></row><row><entry namest="col1" nameend="col1" align="center">64</entry><entry namest="col2" nameend="col2" align="char" char=".">6.125</entry><entry namest="col3" nameend="col3" align="char" char=".">12.875</entry></row><row><entry namest="col1" nameend="col1" align="center">65</entry><entry namest="col2" nameend="col2" align="char" char=".">5.5</entry><entry namest="col3" nameend="col3" align="char" char=".">12.5</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">.</entry><entry namest="col2" nameend="col2" align="char" char=".">.</entry><entry namest="col3" nameend="col3" align="char" char=".">.</entry></row><row><entry namest="col1" nameend="col1" align="center">76</entry><entry namest="col2" nameend="col2" align="char" char=".">8.125</entry><entry namest="col3" nameend="col3" align="char" char=".">12.125</entry></row><row><entry namest="col1" nameend="col1" align="center">77</entry><entry namest="col2" nameend="col2" align="char" char=".">7.75</entry><entry namest="col3" nameend="col3" align="char" char=".">12.75</entry></row><row rowsep="1"><entry namest="col1" nameend="col1" align="center">78</entry><entry namest="col2" nameend="col2" align="char" char=".">7.25</entry><entry namest="col3" nameend="col3" align="char" char=".">13.0</entry></row></tbody></tgroup></table></tables></p>
EP	0604687	B1	2000-04-19	en	CLAIM	1	<claim id="c-en-01-0001" num="0001"><claim-text>A method for deriving character features in a character recognition system for recognising characters, such as letters and digits, the method comprising a step of deriving for each point of a plurality of points in an image plane of image points including a pattern of a character to be recognised feature data indicative of the distance to a nearest boundary point of the pattern,<br/>wherein the plurality of points includes a set (<maths id="math0018" num=""><math display="inline"><mrow><msub><mrow><mtext>R = {R</mtext></mrow><mrow><mtext>i</mtext></mrow></msub><mtext>/i-1,--,N}</mtext></mrow></math><img id="ib0018" file="imgb0018.tif" wi="31" he="6" img-content="math" img-format="tif" inline="yes"/></maths>) of preselected points (R<sub>i</sub>), called reference points, and the method includes a further step of deriving, for each reference point, further feature data (H(R<sub>i</sub>)) indicative of the direction of the boundary in its corresponding nearest boundary point.</claim-text></claim><claim id="c-en-01-0002" num="0002"><claim-text>The method according to Claim 1, characterised in that the boundary points are contour points on a filtered contour (C1, C2), the filtered contour being obtained by steps of contour tracing and filtering, preceeding said first deriving step.</claim-text></claim><claim id="c-en-01-0003" num="0003"><claim-text>The method according to Claim 1 or 2, characterised in that the method comprises a step of determining a feature vector (<maths id="math0019" num=""><math display="inline"><mrow><msub><mrow><mtext>V = {v</mtext></mrow><mrow><mtext>n</mtext></mrow></msub><mtext>}/n=1,--,2N</mtext></mrow></math><img id="ib0019" file="imgb0019.tif" wi="35" he="6" img-content="math" img-format="tif" inline="yes"/></maths>) from said feature data and said further feature data, the feature vector including the distance data (D(R<sub>i</sub>)) and the directional data (H(R<sub>i</sub>)) for each reference point (R<sub>i</sub>) as vector coefficients.</claim-text></claim><claim id="c-en-01-0004" num="0004"><claim-text>The method according to Claim 1, 2 or 3, characterised in that the number of reference points is greater than 70 and less than 120.</claim-text></claim><claim id="c-en-01-0005" num="0005"><claim-text>The method according to any of the Claims 1,--,4, characterised in that the set of reference points includes points randomly distributed in the image plane.</claim-text></claim><claim id="c-en-01-0006" num="0006"><claim-text>The method according to any of the Claims 1,--,4, characterised in that the set of reference points includes points regularly distributed in the image plane.</claim-text></claim><claim id="c-en-01-0007" num="0007"><claim-text>Character recognition system for recognising characters such as letters and digits, which system comprises:<claim-text>- means for recording an image pattern of a character to be recognised on the surface of a carrier,</claim-text><claim-text>- feature derivation means for deriving feature data for a number of character features of the character to be recognised from said recorded image pattern,</claim-text><claim-text>- checking means (101) for checking the derived feature data against results obtained previously on a set of known characters, and<!-- EPO <DP n="24"> --> for outputting checking results,</claim-text><claim-text>- deciding means (102), for deciding, on the basis of the checking results, which known character the character to be recognised is recognised as,<br/>wherein the feature derivation means (FD) include deriving means for deriving, for each point of a set of preselected points, called reference points, in an image plane of said recorded image pattern, feature data indicative of the distance to a nearest boundary point of the pattern, and feature data indicative of the direction of the boundary in its corresponding nearest boundary point.</claim-text></claim-text></claim><claim id="c-en-01-0008" num="0008"><claim-text>Character recognition system according to Claim 7, characterised in that the system further comprises a contour tracer (CD, CF) for locating a contour of the character to be recognised and for determining a contour description of the contour found, the deriving means being arranged for determining, for each reference point (RQ), the distance (<maths id="math0020" num=""><math display="inline"><mrow><mtext>D(RQ) = d</mtext></mrow></math><img id="ib0020" file="imgb0020.tif" wi="21" he="5" img-content="math" img-format="tif" inline="yes"/></maths>) to a nearest contour segment (k), and the direction (H(RQ)), at least as an approximation, of the nearest contour segment.</claim-text></claim>
EP	0604687	B1	2000-04-19	en	PDFEP	1	https://data.epo.org/publication-server/pdf-document?cc=EP&pn=0604687&ki=B1&pd=2000-04-19
